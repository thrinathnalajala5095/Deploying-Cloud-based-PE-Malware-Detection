{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esNWMzKrVuWc"
   },
   "source": [
    "**Step 1:** Mount your Google Drive by clicking on \"Mount Drive\" in the Files section (panel to the left of this text.)\n",
    "\n",
    "**Step 2:** Go to Runtime -> Change runtime type and select TPU.\n",
    "\n",
    "**Step 3:** Create a folder in your Google Drive, and rename it to \"vMalConv\"\n",
    "\n",
    "**Step 4:** Download the pre-processed training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUq_FZwmZegw",
    "outputId": "f04d4f1c-b15a-483d-9ce2-1d594aabfaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-13 20:40:54--  https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/X_train.dat\n",
      "Resolving dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)... 52.219.142.42\n",
      "Connecting to dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)|52.219.142.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8571600000 (8.0G) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘X_train.dat.1’\n",
      "\n",
      "X_train.dat.1       100%[===================>]   7.98G  72.2MB/s    in 1m 49s  \n",
      "\n",
      "2021-10-13 20:42:43 (75.3 MB/s) - ‘X_train.dat.1’ saved [8571600000/8571600000]\n",
      "\n",
      "--2021-10-13 20:42:48--  https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/X_test.dat\n",
      "Resolving dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)... 52.219.88.168\n",
      "Connecting to dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)|52.219.88.168|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1904800000 (1.8G) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘X_test.dat.1’\n",
      "\n",
      "X_test.dat.1        100%[===================>]   1.77G  39.0MB/s    in 27s     \n",
      "\n",
      "2021-10-13 20:43:15 (68.1 MB/s) - ‘X_test.dat.1’ saved [1904800000/1904800000]\n",
      "\n",
      "--2021-10-13 20:43:15--  https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/y_train.dat\n",
      "Resolving dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)... 52.219.100.152\n",
      "Connecting to dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)|52.219.100.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3600000 (3.4M) [binary/octet-stream]\n",
      "Saving to: ‘y_train.dat.1’\n",
      "\n",
      "y_train.dat.1       100%[===================>]   3.43M  16.0MB/s    in 0.2s    \n",
      "\n",
      "2021-10-13 20:43:17 (16.0 MB/s) - ‘y_train.dat.1’ saved [3600000/3600000]\n",
      "\n",
      "--2021-10-13 20:43:18--  https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/y_test.dat\n",
      "Resolving dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)... 52.219.105.90\n",
      "Connecting to dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)|52.219.105.90|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 800000 (781K) [binary/octet-stream]\n",
      "Saving to: ‘y_test.dat.1’\n",
      "\n",
      "y_test.dat.1        100%[===================>] 781.25K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-10-13 20:43:18 (5.61 MB/s) - ‘y_test.dat.1’ saved [800000/800000]\n",
      "\n",
      "--2021-10-13 20:43:18--  https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/metadata.csv\n",
      "Resolving dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)... 52.219.105.90\n",
      "Connecting to dsci6015aisecf21.s3.us-east-2.amazonaws.com (dsci6015aisecf21.s3.us-east-2.amazonaws.com)|52.219.105.90|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 96888920 (92M) [text/csv]\n",
      "Saving to: ‘metadata.csv.1’\n",
      "\n",
      "metadata.csv.1      100%[===================>]  92.40M  89.9MB/s    in 1.0s    \n",
      "\n",
      "2021-10-13 20:43:19 (89.9 MB/s) - ‘metadata.csv.1’ saved [96888920/96888920]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/X_train.dat\n",
    "!wget https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/X_test.dat\n",
    "!wget https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/y_train.dat\n",
    "!wget https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/y_test.dat\n",
    "!wget https://dsci6015aisecf21.s3.us-east-2.amazonaws.com/metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQ_JdZKfG7Q-",
    "outputId": "1b491080-91bb-422e-8707-648e91e66a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V958PbDW3H0"
   },
   "source": [
    "**Step 5:** Copy the downloaded files to vMalConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "llip77F3amma"
   },
   "outputs": [],
   "source": [
    "!cp /content/X_train.dat /content/drive/MyDrive/vMalConv/X_train.dat\n",
    "!cp /content/X_test.dat /content/drive/MyDrive/vMalConv/X_test.dat\n",
    "!cp /content/y_train.dat /content/drive/MyDrive/vMalConv/y_train.dat\n",
    "!cp /content/y_test.dat /content/drive/MyDrive/vMalConv/y_test.dat\n",
    "!cp /content/metadata.csv /content/drive/MyDrive/vMalConv/metadata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbRilyqTXnrE"
   },
   "source": [
    "**Step 6:** Download and install Ember:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76bc7PEmlwKB",
    "outputId": "2724e05e-e6c1-46b4-aea3-e7798aa091d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-13 20:47:47--  https://github.com/endgameinc/ember/archive/master.zip\n",
      "Resolving github.com (github.com)... 140.82.114.4\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://github.com/elastic/ember/archive/master.zip [following]\n",
      "--2021-10-13 20:47:47--  https://github.com/elastic/ember/archive/master.zip\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/elastic/ember/zip/master [following]\n",
      "--2021-10-13 20:47:47--  https://codeload.github.com/elastic/ember/zip/master\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11769696 (11M) [application/zip]\n",
      "Saving to: ‘master.zip’\n",
      "\n",
      "master.zip          100%[===================>]  11.22M  18.3MB/s    in 0.6s    \n",
      "\n",
      "2021-10-13 20:47:48 (18.3 MB/s) - ‘master.zip’ saved [11769696/11769696]\n",
      "\n",
      "Archive:  master.zip\n",
      "4dee42918694d72d319e731940755146a71f5c6c\n",
      "   creating: ember-master/\n",
      "  inflating: ember-master/LICENSE.txt  \n",
      "  inflating: ember-master/README.md  \n",
      "   creating: ember-master/ember/\n",
      "  inflating: ember-master/ember/__init__.py  \n",
      "  inflating: ember-master/ember/features.py  \n",
      "   creating: ember-master/licenses/\n",
      "  inflating: ember-master/licenses/AGPL-LICENSE-3.0.txt  \n",
      "  inflating: ember-master/licenses/MIT-LICENSE.txt  \n",
      "   creating: ember-master/malconv/\n",
      "  inflating: ember-master/malconv/README.md  \n",
      "  inflating: ember-master/malconv/malconv.h5  \n",
      "  inflating: ember-master/malconv/malconv.py  \n",
      "  inflating: ember-master/malconv/multi_gpu.py  \n",
      "  inflating: ember-master/requirements.txt  \n",
      "  inflating: ember-master/requirements_conda.txt  \n",
      "  inflating: ember-master/requirements_notebook.txt  \n",
      "   creating: ember-master/resources/\n",
      "  inflating: ember-master/resources/ember-notebook.ipynb  \n",
      "  inflating: ember-master/resources/ember2018-notebook.ipynb  \n",
      "  inflating: ember-master/resources/logo.png  \n",
      "   creating: ember-master/scripts/\n",
      "  inflating: ember-master/scripts/classify_binaries.py  \n",
      "  inflating: ember-master/scripts/init_ember.py  \n",
      "  inflating: ember-master/setup.py   \n",
      "Requirement already satisfied: lief>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.11.5)\n",
      "Requirement already satisfied: tqdm>=4.31.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.1.5)\n",
      "Requirement already satisfied: lightgbm>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.22.2.post1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.2.3->-r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.3->-r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->-r requirements.txt (line 4)) (1.15.0)\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing ember.egg-info/PKG-INFO\n",
      "writing dependency_links to ember.egg-info/dependency_links.txt\n",
      "writing requirements to ember.egg-info/requires.txt\n",
      "writing top-level names to ember.egg-info/top_level.txt\n",
      "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE.txt'\n",
      "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying ember/features.py -> build/lib/ember\n",
      "copying ember/__init__.py -> build/lib/ember\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/ember\n",
      "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
      "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
      "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/ember-0.1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing ember-0.1.0-py3.7.egg\n",
      "Removing /usr/local/lib/python3.7/dist-packages/ember-0.1.0-py3.7.egg\n",
      "Copying ember-0.1.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "ember 0.1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/ember-0.1.0-py3.7.egg\n",
      "Processing dependencies for ember==0.1.0\n",
      "Searching for scikit-learn==0.22.2.post1\n",
      "Best match: scikit-learn 0.22.2.post1\n",
      "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for lightgbm==2.2.3\n",
      "Best match: lightgbm 2.2.3\n",
      "Adding lightgbm 2.2.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pandas==1.1.5\n",
      "Best match: pandas 1.1.5\n",
      "Adding pandas 1.1.5 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for numpy==1.19.5\n",
      "Best match: numpy 1.19.5\n",
      "Adding numpy 1.19.5 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.7 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for tqdm==4.62.3\n",
      "Best match: tqdm 4.62.3\n",
      "Adding tqdm 4.62.3 to easy-install.pth file\n",
      "Installing tqdm script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for lief==0.11.5\n",
      "Best match: lief 0.11.5\n",
      "Adding lief 0.11.5 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for joblib==1.0.1\n",
      "Best match: joblib 1.0.1\n",
      "Adding joblib 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for scipy==1.4.1\n",
      "Best match: scipy 1.4.1\n",
      "Adding scipy 1.4.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pytz==2018.9\n",
      "Best match: pytz 2018.9\n",
      "Adding pytz 2018.9 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Finished processing dependencies for ember==0.1.0\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/endgameinc/ember/archive/master.zip\n",
    "!unzip master.zip\n",
    "!rm master.zip\n",
    "!cp -r ember-master/* .\n",
    "!rm -r ember-master\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXym5qd8Yv8f"
   },
   "source": [
    "**Step 7:** Read vectorized features from the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfcHyoTsmCFH",
    "outputId": "e81909a3-aac6-409f-f182-bb503310cf14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.11.5-37bc2c9 found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import ember\n",
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"drive/MyDrive/vMalConv/\")\n",
    "metadata_dataframe = ember.read_metadata(\"drive/MyDrive/vMalConv/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTRCz7m7Z7EH"
   },
   "source": [
    "**Step 7:** Get rid of rows with no labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Zj63lcvin44q"
   },
   "outputs": [],
   "source": [
    "labelrows = (y_train != -1)\n",
    "X_train = X_train[labelrows]\n",
    "y_train = y_train[labelrows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mVG59AGooyC5"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('X_train.h5', 'w')\n",
    "h5f.create_dataset('X_train', data=X_train)\n",
    "h5f.close()\n",
    "h5f = h5py.File('y_train.h5', 'w')\n",
    "h5f.create_dataset('y_train', data=y_train)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5tmUIJNvpZch"
   },
   "outputs": [],
   "source": [
    "!cp /content/X_train.h5 /content/drive/MyDrive/vMalConv/X_train.h5\n",
    "!cp /content/y_train.h5 /content/drive/MyDrive/vMalConv/y_train.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1bRlBWlaQdd"
   },
   "source": [
    "> **Exercise 1:** Complete the following code to create the architecture of MalConv in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "K1UTVZi0qkGe"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "  import tensorflow as tf\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "  feature_size=2381\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "  keras.backend.clear_session()\n",
    "  \n",
    "  # Model architecture\n",
    "  from tensorflow.keras import layers\n",
    "  model = tf.keras.Sequential()\n",
    "  ### Your code -- Define the layers of MalConv ###\n",
    "  model.add(layers.InputLayer(input_shape=(1,feature_size)))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(1500, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
    "  print(model.summary())\n",
    "  return model\n",
    " \n",
    "\n",
    "  model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
    "  print(model.summary())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1ZlKQwDv4uz",
    "outputId": "de9a75e7-ab45-4607-8b21-3a02c7556f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 1, 2381)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 1500)           3573000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1500)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1)              1501      \n",
      "=================================================================\n",
      "Total params: 3,574,501\n",
      "Trainable params: 3,574,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pihnLcFmbaet"
   },
   "source": [
    "**Step 8:** Partial fit the standardScaler to avoid overloading the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "H4q5OfK9v9iN"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mms = StandardScaler()\n",
    "for x in range(0,600000,100000):\n",
    "  mms.partial_fit(X_train[x:x+100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "B33Oa1sTxdB0"
   },
   "outputs": [],
   "source": [
    "X_train = mms.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "V_vl5yrex0yY"
   },
   "outputs": [],
   "source": [
    "## Reshape to create 3 channels ##\n",
    "import numpy as np\n",
    "X_train = np.reshape(X_train,(-1,1,2381))\n",
    "y_train = np.reshape(y_train,(-1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zMgth6McCqV"
   },
   "source": [
    "> **Exercise 2:** Complete the following code to train the model for 30 epochs, with a batch size of 128, and 20% validation split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IncS7YgW6xJZ",
    "outputId": "ea8a2ab8-0e32-43ba-9ef0-5b446650525e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/30\n",
      "480000/480000 [==============================] - ETA: 0s - loss: 6.7321 - accuracy: 0.9417 - auc_1: 0.9479 - precision_1: 0.9406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480000/480000 [==============================] - 235s 490us/sample - loss: 6.7321 - accuracy: 0.9417 - auc_1: 0.9479 - precision_1: 0.9406 - val_loss: 4.5403 - val_accuracy: 0.9708 - val_auc_1: 0.9732 - val_precision_1: 0.9885\n",
      "Epoch 2/30\n",
      "480000/480000 [==============================] - 308s 642us/sample - loss: 9.9135 - accuracy: 0.9579 - auc_1: 0.9613 - precision_1: 0.9568 - val_loss: 4.6800 - val_accuracy: 0.9825 - val_auc_1: 0.9852 - val_precision_1: 0.9887\n",
      "Epoch 3/30\n",
      "480000/480000 [==============================] - 243s 507us/sample - loss: 12.4231 - accuracy: 0.9626 - auc_1: 0.9657 - precision_1: 0.9617 - val_loss: 6.7781 - val_accuracy: 0.9835 - val_auc_1: 0.9887 - val_precision_1: 0.9915\n",
      "Epoch 4/30\n",
      "480000/480000 [==============================] - 107s 223us/sample - loss: 10.6821 - accuracy: 0.9664 - auc_1: 0.9709 - precision_1: 0.9650 - val_loss: 4.9982 - val_accuracy: 0.9867 - val_auc_1: 0.9904 - val_precision_1: 0.9898\n",
      "Epoch 5/30\n",
      "480000/480000 [==============================] - 245s 511us/sample - loss: 9.4333 - accuracy: 0.9670 - auc_1: 0.9716 - precision_1: 0.9656 - val_loss: 4.9928 - val_accuracy: 0.9852 - val_auc_1: 0.9887 - val_precision_1: 0.9880\n",
      "Epoch 6/30\n",
      "480000/480000 [==============================] - 145s 303us/sample - loss: 10.4925 - accuracy: 0.9677 - auc_1: 0.9728 - precision_1: 0.9659 - val_loss: 6.4537 - val_accuracy: 0.9860 - val_auc_1: 0.9915 - val_precision_1: 0.9925\n",
      "Epoch 7/30\n",
      "480000/480000 [==============================] - 311s 648us/sample - loss: 8.7636 - accuracy: 0.9690 - auc_1: 0.9745 - precision_1: 0.9670 - val_loss: 5.5945 - val_accuracy: 0.9855 - val_auc_1: 0.9909 - val_precision_1: 0.9909\n",
      "Epoch 8/30\n",
      "480000/480000 [==============================] - 220s 459us/sample - loss: 10.7653 - accuracy: 0.9693 - auc_1: 0.9750 - precision_1: 0.9668 - val_loss: 6.1591 - val_accuracy: 0.9858 - val_auc_1: 0.9907 - val_precision_1: 0.9909\n",
      "Epoch 9/30\n",
      "480000/480000 [==============================] - 311s 648us/sample - loss: 11.2982 - accuracy: 0.9698 - auc_1: 0.9757 - precision_1: 0.9672 - val_loss: 7.8894 - val_accuracy: 0.9870 - val_auc_1: 0.9910 - val_precision_1: 0.9912\n",
      "Epoch 10/30\n",
      "480000/480000 [==============================] - 237s 495us/sample - loss: 10.8513 - accuracy: 0.9704 - auc_1: 0.9771 - precision_1: 0.9680 - val_loss: 8.3012 - val_accuracy: 0.9868 - val_auc_1: 0.9909 - val_precision_1: 0.9899\n",
      "Epoch 11/30\n",
      "480000/480000 [==============================] - 344s 718us/sample - loss: 12.0301 - accuracy: 0.9693 - auc_1: 0.9774 - precision_1: 0.9663 - val_loss: 7.4477 - val_accuracy: 0.9872 - val_auc_1: 0.9917 - val_precision_1: 0.9878\n",
      "model saved.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "save_dir = \"drive/MyDrive/vMalConv/\"\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "### Your code ###\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                batch_size=128,\n",
    "                epochs=30,\n",
    "                  validation_split=.2,\n",
    "                  callbacks=[callback]\n",
    "                  )\n",
    "# Save the weights #\n",
    "model.save_weights (save_dir+'weights.h5')\n",
    "\n",
    "# Save the model architecture #\n",
    "model_json = model.to_json()\n",
    "with open(save_dir+\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "om_qWZMvebjB"
   },
   "source": [
    "**Final Steps:** Download this Jupyter Notebook, and the saved model files."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Colab_Training_F21.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
